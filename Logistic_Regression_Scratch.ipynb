{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA2nsAEMdDzgYQxVJwmzX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/najmanmna/loan-predict/blob/main/Logistic_Regression_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmFuUKvJcFwh",
        "outputId": "2591acc8-0c34-4ba4-cd4c-b2f2d04cab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at threshold 0.4: 0.7986111111111112\n",
            "Confusion Matrix:\n",
            "[[ 15.  29.]\n",
            " [  0. 100.]]\n",
            "Classification Report:\n",
            "{'precision': array([1.       , 0.7751938]), 'recall': array([0.34090909, 1.        ]), 'f1-score': array([0.50847458, 0.87336245]), 'support': array([ 44., 100.])}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/sample_data/loan_sanction_train.csv')\n",
        "\n",
        "# Drop the 'Loan_ID' column and rows with any null values\n",
        "df = df.drop(['Loan_ID'], axis=1).dropna()\n",
        "\n",
        "# Identify categorical columns (dtype 'object' or 'category') and apply one-hot encoding\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "# Convert all columns to integers\n",
        "df_encoded = df_encoded.astype(int)\n",
        "\n",
        "# Drop the 'Loan_Status_N' column and separate features and target\n",
        "df_encoded = df_encoded.drop('Loan_Status_N', axis=1)\n",
        "X = df_encoded.drop('Loan_Status_Y', axis=1).values\n",
        "y = df_encoded['Loan_Status_Y'].values\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "def train_test_split(X, y, test_size=0.3, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    test_size = int(len(X) * test_size)\n",
        "    test_indices = indices[:test_size]\n",
        "    train_indices = indices[test_size:]\n",
        "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Sigmoid function with overflow prevention\n",
        "def sigmoid(z):\n",
        "    return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n",
        "\n",
        "# Logistic Regression model class\n",
        "class LogisticRegressionScratch:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.m, self.n = X.shape\n",
        "        self.theta = np.zeros(self.n)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            model = np.dot(X, self.theta) + self.bias\n",
        "            y_predicted = sigmoid(model)\n",
        "\n",
        "            d_theta = (1 / self.m) * np.dot(X.T, (y_predicted - y))\n",
        "            d_bias = (1 / self.m) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.theta -= self.learning_rate * d_theta\n",
        "            self.bias -= self.learning_rate * d_bias\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        model = np.dot(X, self.theta) + self.bias\n",
        "        return sigmoid(model)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        y_predicted = self.predict_prob(X)\n",
        "        return [1 if i > threshold else 0 for i in y_predicted]\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegressionScratch(learning_rate=0.01, epochs=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate with threshold 0.4\n",
        "y_prob = model.predict_prob(X_test)\n",
        "\n",
        "# Evaluate at threshold 0.4\n",
        "threshold = 0.4\n",
        "y_pred = [1 if i > threshold else 0 for i in y_prob]\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "print(f'Accuracy at threshold {threshold}: {accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "# Define confusion matrix function\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "    K = len(np.unique(y_true))  # Number of classes\n",
        "    result = np.zeros((K, K))\n",
        "    for i in range(len(y_true)):\n",
        "        result[y_true[i]][y_pred[i]] += 1\n",
        "    return result\n",
        "\n",
        "# Define classification report function\n",
        "def classification_report(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tp = np.diag(cm)\n",
        "    precision = np.divide(tp, np.sum(cm, axis=0), where=np.sum(cm, axis=0) != 0)\n",
        "    recall = np.divide(tp, np.sum(cm, axis=1), where=np.sum(cm, axis=1) != 0)\n",
        "    f1 = 2 * np.divide(precision * recall, precision + recall, where=(precision + recall) != 0)\n",
        "    report = {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1-score': f1,\n",
        "        'support': np.sum(cm, axis=1)\n",
        "    }\n",
        "    return report\n",
        "\n",
        "# Predict and evaluate with threshold 0.4\n",
        "y_pred = model.predict(X_test, threshold=0.4)\n",
        "\n",
        "# Calculate confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{class_report}')\n"
      ]
    }
  ]
}